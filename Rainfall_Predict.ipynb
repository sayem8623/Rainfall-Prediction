{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "source": [
        "!pip install catboost\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import itertools\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "import xgboost as xgb\n",
        "from mlxtend.classifier import EnsembleVoteClassifier\n",
        "from mlxtend.plotting import plot_decision_regions"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH16chPsskTU",
        "outputId": "152bdaa6-31ac-4688-8cea-754b7f66b865"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Data"
      ],
      "metadata": {
        "id": "dkv4IbJi0ozD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "8y3_UoDfs4Jh",
        "outputId": "9e348954-52c9-4268-af36-f24197684b85"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ]
    },
    {
      "source": [
        "import pandas as pd # Importing the pandas library\n",
        "\n",
        "full_data= pd.read_csv('/content/drive/MyDrive/Sayem/weatherAUS.csv',header=0 )\n",
        "full_data"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "kwHke-UgtKBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_data.head(10)"
      ],
      "metadata": {
        "id": "_woLNGaM0uAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_data.shape"
      ],
      "metadata": {
        "id": "C8RnIK51qp4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_data.info()"
      ],
      "metadata": {
        "id": "5R4fEK07qvuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_data['RainToday'].replace({'No': 0, 'Yes': 1},inplace = True)\n",
        "full_data['RainTomorrow'].replace({'No': 0, 'Yes': 1},inplace = True)"
      ],
      "metadata": {
        "id": "yeupnqQKqyZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize = (8,5))\n",
        "full_data.RainTomorrow.value_counts(normalize = True).plot(kind='bar', color= ['skyblue','navy'], alpha = 0.9, rot=0)\n",
        "plt.title('RainTomorrow Indicator No(0) and Yes(1) in the Imbalanced Dataset')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAssK5XUq1R3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Handling Class Imbalance"
      ],
      "metadata": {
        "id": "5tKAKtHs1e8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "no = full_data[full_data.RainTomorrow == 0]\n",
        "yes = full_data[full_data.RainTomorrow == 1]\n",
        "yes_oversampled = resample(yes, replace=True, n_samples=len(no), random_state=123)\n",
        "oversampled = pd.concat([no, yes_oversampled])\n",
        "\n",
        "fig = plt.figure(figsize = (8,5))\n",
        "oversampled.RainTomorrow.value_counts(normalize = True).plot(kind='bar', color= ['skyblue','navy'], alpha = 0.9, rot=0)\n",
        "plt.title('RainTomorrow Indicator No(0) and Yes(1) after Oversampling (Balanced Dataset)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h1DvebzLq381"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Data Pattern in Training Data\n",
        "import seaborn as sns\n",
        "sns.heatmap(oversampled.isnull(), cbar=False, cmap='PuBu')"
      ],
      "metadata": {
        "id": "R-pt1Yo2rDB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total = oversampled.isnull().sum().sort_values(ascending=False)\n",
        "percent = (oversampled.isnull().sum()/oversampled.isnull().count()).sort_values(ascending=False)\n",
        "missing = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "missing.head(4)"
      ],
      "metadata": {
        "id": "RRFfxoZ-rGDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imputation and Transformation"
      ],
      "metadata": {
        "id": "lnzHA_M31THC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oversampled.select_dtypes(include=['object']).columns"
      ],
      "metadata": {
        "id": "KIImpMH-rG9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute categorical var with Mode\n",
        "oversampled['Date'] = oversampled['Date'].fillna(oversampled['Date'].mode()[0])\n",
        "oversampled['Location'] = oversampled['Location'].fillna(oversampled['Location'].mode()[0])\n",
        "oversampled['WindGustDir'] = oversampled['WindGustDir'].fillna(oversampled['WindGustDir'].mode()[0])\n",
        "oversampled['WindDir9am'] = oversampled['WindDir9am'].fillna(oversampled['WindDir9am'].mode()[0])\n",
        "oversampled['WindDir3pm'] = oversampled['WindDir3pm'].fillna(oversampled['WindDir3pm'].mode()[0])"
      ],
      "metadata": {
        "id": "z4CP_kOmrNXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical features to continuous features with Label Encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lencoders = {}\n",
        "for col in oversampled.select_dtypes(include=['object']).columns:\n",
        "    lencoders[col] = LabelEncoder()\n",
        "    oversampled[col] = lencoders[col].fit_transform(oversampled[col])"
      ],
      "metadata": {
        "id": "WGvfSc-PrRu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# Multiple Imputation by Chained Equations\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "MiceImputed = oversampled.copy(deep=True)\n",
        "mice_imputer = IterativeImputer()\n",
        "MiceImputed.iloc[:, :] = mice_imputer.fit_transform(oversampled)"
      ],
      "metadata": {
        "id": "jme46GgRrUoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detecting outliers with IQR\n",
        "Q1 = MiceImputed.quantile(0.25)\n",
        "Q3 = MiceImputed.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "print(IQR)"
      ],
      "metadata": {
        "id": "3UFl0PiMrW8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing outliers from the dataset\n",
        "MiceImputed = MiceImputed[~((MiceImputed < (Q1 - 1.5 * IQR)) |(MiceImputed > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "MiceImputed.shape"
      ],
      "metadata": {
        "id": "IVdrf8F2rZot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "corr = MiceImputed.corr()\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "f, ax = plt.subplots(figsize=(20, 20))\n",
        "cmap = sns.diverging_palette(250, 25, as_cmap=True)\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=None, center=0,square=True, annot=True, linewidths=.5, cbar_kws={\"shrink\": .9})"
      ],
      "metadata": {
        "id": "cekhjfcsrdJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot( data=MiceImputed, vars=('MaxTemp','MinTemp','Pressure9am','Pressure3pm', 'Temp9am', 'Temp3pm', 'Evaporation'), hue='RainTomorrow')"
      ],
      "metadata": {
        "id": "KFvOv2K0rgpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Selection for Rainfall Prediction"
      ],
      "metadata": {
        "id": "bmZfJ9mx1HYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "r_scaler = preprocessing.MinMaxScaler()\n",
        "r_scaler.fit(MiceImputed)\n",
        "modified_data = pd.DataFrame(r_scaler.transform(MiceImputed), index=MiceImputed.index, columns=MiceImputed.columns)"
      ],
      "metadata": {
        "id": "IJVv6NSwrq2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Importance using Filter Method (Chi-Square)\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "X = modified_data.loc[:,modified_data.columns!='RainTomorrow']\n",
        "y = modified_data[['RainTomorrow']]\n",
        "selector = SelectKBest(chi2, k=10)\n",
        "selector.fit(X, y)\n",
        "X_new = selector.transform(X)\n",
        "print(X.columns[selector.get_support(indices=True)])\n"
      ],
      "metadata": {
        "id": "qsf8kxlyruRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier as rf\n",
        "\n",
        "X = MiceImputed.drop('RainTomorrow', axis=1)\n",
        "y = MiceImputed['RainTomorrow']\n",
        "selector = SelectFromModel(rf(n_estimators=100, random_state=0))\n",
        "selector.fit(X, y)\n",
        "support = selector.get_support()\n",
        "features = X.loc[:,support].columns.tolist()\n",
        "print(features)\n",
        "print(rf(n_estimators=100, random_state=0).fit(X,y).feature_importances_)"
      ],
      "metadata": {
        "id": "_2KrdZWvrxYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Rainfall Prediction Model with Different Models"
      ],
      "metadata": {
        "id": "hTwOoYhA1t_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = MiceImputed[['Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustDir',\n",
        "                       'WindGustSpeed', 'WindDir9am', 'WindDir3pm', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n",
        "                       'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm',\n",
        "                       'RainToday']]\n",
        "target = MiceImputed['RainTomorrow']\n",
        "\n",
        "# Split into test and train\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=12345)\n",
        "\n",
        "# Normalize Features\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "0Og9Hj1Cr0pW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc_cur(fper, tper):\n",
        "    plt.plot(fper, tper, color='orange', label='ROC')\n",
        "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "PODPd0Hor2q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import time\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, cohen_kappa_score, roc_curve, classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay # Import ConfusionMatrixDisplay\n",
        "\n",
        "def run_model(model, X_train, y_train, X_test, y_test, verbose=True):\n",
        "    t0=time.time()\n",
        "    if verbose == False:\n",
        "        model.fit(X_train,y_train, verbose=0)\n",
        "    else:\n",
        "        model.fit(X_train,y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred)\n",
        "    coh_kap = cohen_kappa_score(y_test, y_pred)\n",
        "    time_taken = time.time()-t0\n",
        "    print(\"Accuracy = {}\".format(accuracy))\n",
        "    print(\"ROC Area under Curve = {}\".format(roc_auc))\n",
        "    print(\"Cohen's Kappa = {}\".format(coh_kap))\n",
        "    print(\"Time taken = {}\".format(time_taken))\n",
        "    print(classification_report(y_test,y_pred,digits=5))\n",
        "\n",
        "    probs = model.predict_proba(X_test)\n",
        "    probs = probs[:, 1]\n",
        "    fper, tper, thresholds = roc_curve(y_test, probs)\n",
        "    plot_roc_cur(fper, tper)\n",
        "\n",
        "    # Use ConfusionMatrixDisplay instead of plot_confusion_matrix\n",
        "    cm = ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, cmap=plt.cm.Blues, normalize='all')\n",
        "    cm.plot()\n",
        "    plt.show()\n",
        "\n",
        "    return model, accuracy, roc_auc, coh_kap, time_taken"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "L-9DoOk3zMoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "DGrBkepxWZjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "params_lr = {'penalty': 'l1', 'solver':'liblinear'}\n",
        "\n",
        "model_lr = LogisticRegression(**params_lr)\n",
        "model_lr, accuracy_lr, roc_auc_lr, coh_kap_lr, tt_lr = run_model(model_lr, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "0wqAyC4P30d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree"
      ],
      "metadata": {
        "id": "aRZvw3WWWiIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "params_dt = {'max_depth': 16,\n",
        "             'max_features': \"sqrt\"}\n",
        "\n",
        "model_dt = DecisionTreeClassifier(**params_dt)\n",
        "model_dt, accuracy_dt, roc_auc_dt, coh_kap_dt, tt_dt = run_model(model_dt, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "zL9NK8S33_e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "3G9cjz7LWkom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "params_rf = {'max_depth': 16,\n",
        "             'min_samples_leaf': 1,\n",
        "             'min_samples_split': 2,\n",
        "             'n_estimators': 100,\n",
        "             'random_state': 12345}\n",
        "\n",
        "model_rf = RandomForestClassifier(**params_rf)\n",
        "model_rf, accuracy_rf, roc_auc_rf, coh_kap_rf, tt_rf = run_model(model_rf, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "N_sNxtQY4ME8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Light GBM"
      ],
      "metadata": {
        "id": "pu7ZfzY1WnH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import lightgbm as lgb\n",
        "params_lgb ={'colsample_bytree': 0.95,\n",
        "         'max_depth': 16,\n",
        "         'min_split_gain': 0.1,\n",
        "         'n_estimators': 200,\n",
        "         'num_leaves': 50,\n",
        "         'reg_alpha': 1.2,\n",
        "         'reg_lambda': 1.2,\n",
        "         'subsample': 0.95,\n",
        "         'subsample_freq': 20}\n",
        "\n",
        "model_lgb = lgb.LGBMClassifier(**params_lgb)\n",
        "model_lgb, accuracy_lgb, roc_auc_lgb, coh_kap_lgb, tt_lgb = run_model(model_lgb, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "0GDQyiEv4mBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Catboost"
      ],
      "metadata": {
        "id": "HkBC9F1rWp_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install catboost\n",
        "import catboost as cb\n",
        "params_cb ={'iterations': 50,\n",
        "            'max_depth': 16}\n",
        "\n",
        "model_cb = cb.CatBoostClassifier(**params_cb)\n",
        "model_cb, accuracy_cb, roc_auc_cb, coh_kap_cb, tt_cb = run_model(model_cb, X_train, y_train, X_test, y_test, verbose=False)"
      ],
      "metadata": {
        "id": "6MwQiFzX4q0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, cohen_kappa_score, roc_curve, classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay # Import ConfusionMatrixDisplay\n",
        "\n",
        "def run_model(model, X_train, y_train, X_test, y_test, verbose=True):\n",
        "    t0=time.time()\n",
        "    if verbose == False:\n",
        "        model.fit(X_train,y_train, verbose=0)\n",
        "    else:\n",
        "        model.fit(X_train,y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred)\n",
        "    # coh_kap = cohen_kappa_score(y_test, y_pred) # Removing cohen_kappa_score calculation\n",
        "    time_taken = time.time()-t0\n",
        "    print(\"Accuracy = {}\".format(accuracy))\n",
        "    print(\"ROC Area under Curve = {}\".format(roc_auc))\n",
        "    # print(\"Cohen's Kappa = {}\".format(coh_kap)) # Removing cohen_kappa_score print\n",
        "    print(\"Time taken = {}\".format(time_taken))\n",
        "    print(classification_report(y_test,y_pred,digits=5))\n",
        "\n",
        "    probs = model.predict_proba(X_test)\n",
        "    probs = probs[:, 1]\n",
        "    fper, tper, thresholds = roc_curve(y_test, probs)\n",
        "    plot_roc_cur(fper, tper)\n",
        "\n",
        "    # Use ConfusionMatrixDisplay instead of plot_confusion_matrix\n",
        "    cm = ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, cmap=plt.cm.Blues, normalize='all')\n",
        "    cm.plot()\n",
        "    plt.show()\n",
        "\n",
        "    return model, accuracy, roc_auc, time_taken # Returning only necessary values"
      ],
      "metadata": {
        "id": "o-KFycml-OSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plotting Decision Region for all Models"
      ],
      "metadata": {
        "id": "kt8GPDH_2JK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import itertools\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "import xgboost as xgb\n",
        "from mlxtend.classifier import EnsembleVoteClassifier\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "value = 1.80\n",
        "width = 0.90\n",
        "\n",
        "clf1 = LogisticRegression(random_state=12345)\n",
        "clf2 = DecisionTreeClassifier(random_state=12345)\n",
        "clf3 = MLPClassifier(random_state=12345, verbose = 0)\n",
        "clf4 = RandomForestClassifier(random_state=12345)\n",
        "clf5 = lgb.LGBMClassifier(random_state=12345, verbose = 0)\n",
        "clf6 = cb.CatBoostClassifier(random_state=12345, verbose = 0)\n",
        "clf7 = xgb.XGBClassifier(random_state=12345)\n",
        "eclf = EnsembleVoteClassifier(clfs=[clf4, clf5, clf6, clf7], weights=[1, 1, 1, 1], voting='soft')\n",
        "\n",
        "X_list = MiceImputed[[\"Sunshine\", \"Humidity9am\", \"Cloud3pm\"]] #took only really important features\n",
        "X = np.asarray(X_list, dtype=np.float32)\n",
        "y_list = MiceImputed[\"RainTomorrow\"]\n",
        "y = np.asarray(y_list, dtype=np.int32)\n",
        "\n",
        "# Plotting Decision Regions\n",
        "gs = gridspec.GridSpec(3,3)\n",
        "fig = plt.figure(figsize=(18, 14))\n",
        "\n",
        "labels = ['Logistic Regression',\n",
        "          'Decision Tree',\n",
        "          'Neural Network',\n",
        "          'Random Forest',\n",
        "          'LightGBM',\n",
        "          'CatBoost',\n",
        "          'XGBoost',\n",
        "          'Ensemble']\n",
        "\n",
        "for clf, lab, grd in zip([clf1, clf2, clf3, clf4, clf5, clf6, clf7, eclf],\n",
        "                         labels,\n",
        "                         itertools.product([0, 1, 2],\n",
        "                         repeat=2)):\n",
        "    clf.fit(X, y)\n",
        "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
        "    fig = plot_decision_regions(X=X, y=y, clf=clf,\n",
        "                                filler_feature_values={2: value},\n",
        "                                filler_feature_ranges={2: width},\n",
        "                                legend=2)\n",
        "    plt.title(lab)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TB2GTQj8sCij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rainfall Prediction Model Comparison"
      ],
      "metadata": {
        "id": "kIKyauZr16mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = [accuracy_lr, accuracy_dt, accuracy_nn, accuracy_rf, accuracy_lgb, accuracy_cb]\n",
        "roc_auc_scores = [roc_auc_lr, roc_auc_dt, roc_auc_nn, roc_auc_rf, roc_auc_lgb, roc_auc_cb]\n",
        "coh_kap_scores = [coh_kap_lr, coh_kap_dt, coh_kap_nn, coh_kap_rf, coh_kap_lgb, coh_kap_cb]\n",
        "tt = [tt_lr, tt_dt, tt_nn, tt_rf, tt_lgb, tt_cb]\n",
        "\n",
        "# Adjust the 'Model' list to match the length of other lists\n",
        "model_data = {'Model': ['Logistic Regression','Decision Tree','Neural Network','Random Forest','LightGBM','Catboost'], # Removed 'XGBoost'\n",
        "              'Accuracy': accuracy_scores,\n",
        "              'ROC_AUC': roc_auc_scores,\n",
        "              'Cohen_Kappa': coh_kap_scores,\n",
        "              'Time taken': tt}\n",
        "data = pd.DataFrame(model_data)\n",
        "\n",
        "# ... (Rest of your plotting code) ..."
      ],
      "metadata": {
        "id": "lFUHNOB1CfpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, ax1 = plt.subplots(figsize=(12,10))\n",
        "ax1.set_title('Model Comparison: Accuracy and Time taken for execution', fontsize=13)\n",
        "color = 'tab:green'\n",
        "ax1.set_xlabel('Model', fontsize=13)\n",
        "ax1.set_ylabel('Time taken', fontsize=13, color=color)\n",
        "ax2 = sns.barplot(x='Model', y='Time taken', data = data, palette='summer')\n",
        "ax1.tick_params(axis='y')\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:red'\n",
        "ax2.set_ylabel('Accuracy', fontsize=13, color=color)\n",
        "ax2 = sns.lineplot(x='Model', y='Accuracy', data = data, sort=False, color=color)\n",
        "ax2.tick_params(axis='y', color=color)"
      ],
      "metadata": {
        "id": "e2EEEJR9sF7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax3 = plt.subplots(figsize=(12,10))\n",
        "ax3.set_title('Model Comparison: Area under ROC and Cohens Kappa', fontsize=13)\n",
        "color = 'tab:blue'\n",
        "ax3.set_xlabel('Model', fontsize=13)\n",
        "ax3.set_ylabel('ROC_AUC', fontsize=13, color=color)\n",
        "ax4 = sns.barplot(x='Model', y='ROC_AUC', data = data, palette='winter')\n",
        "ax3.tick_params(axis='y')\n",
        "ax4 = ax3.twinx()\n",
        "color = 'tab:red'\n",
        "ax4.set_ylabel('Cohen_Kappa', fontsize=13, color=color)\n",
        "ax4 = sns.lineplot(x='Model', y='Cohen_Kappa', data = data, sort=False, color=color)\n",
        "ax4.tick_params(axis='y', color=color)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QWCgv98csIji"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}